{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from config_paths import PATHS, AUX_PATHS\n",
    "from data_utils import import_data, preprocessing\n",
    "from data_prep import split_data, create_sequences, validate_dimensions\n",
    "\n",
    "SEQ_LEN = 10\n",
    "FORECAST_H = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 1895 timestamps and 2309 Time Series for ESTABLE.\n",
      "Preprocessed data for ESTABLE. 2309 TimeSeries and 1195 TimeStamps.\n",
      "------------------------------------------------------\n",
      "Importing 2131 timestamps and 9270 Time Series for INCENDIO.\n",
      "Preprocessed data for INCENDIO. 9270 TimeSeries and 1195 TimeStamps.\n",
      "------------------------------------------------------\n",
      "Importing 2370 timestamps and 6666 Time Series for SEQUIA.\n",
      "Preprocessed data for SEQUIA. 6666 TimeSeries and 1195 TimeStamps.\n",
      "------------------------------------------------------\n",
      "Importing 1801 timestamps and 6411 Time Series for TALA.\n",
      "Preprocessed data for TALA. 6411 TimeSeries and 1195 TimeStamps.\n",
      "------------------------------------------------------\n",
      "Importing 1689 timestamps and 2441 Time Series for VARIOS.\n",
      "Preprocessed data for VARIOS. 2441 TimeSeries and 1195 TimeStamps.\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "for name in PATHS.keys():\n",
    "    df_dict[name] = import_data(name, paths=PATHS, aux_paths=AUX_PATHS).pipe(\n",
    "        preprocessing, name=name, filter_id=4\n",
    "    )\n",
    "    print(\"------------------------------------------------------\")\n",
    "\n",
    "train_df_dict, test_df_dict = split_data(df_dict, paths=PATHS, date=\"2016-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sequences for ESTABLE: 1893380\n",
      "-----------------------------------------------------\n",
      "Train Sequences for INCENDIO: 7601400\n",
      "-----------------------------------------------------\n",
      "Train Sequences for SEQUIA: 5466120\n",
      "-----------------------------------------------------\n",
      "Train Sequences for TALA: 5257020\n",
      "-----------------------------------------------------\n",
      "Train Sequences for VARIOS: 2001620\n",
      "-----------------------------------------------------\n",
      "==========================================================\n",
      "22219540 total Train sequences generated.\n",
      "22219540 total Train dates generated.\n",
      "22219540 total Train indices generated.\n",
      "==========================================================\n",
      "22219540 total Train targets generated.\n",
      "22219540 total Train target dates generated.\n",
      "22219540 total Train target indices generated.\n",
      "==========================================================\n",
      "Test Sequences for ESTABLE: 819695\n",
      "-----------------------------------------------------\n",
      "Test Sequences for INCENDIO: 3290850\n",
      "-----------------------------------------------------\n",
      "Test Sequences for SEQUIA: 2366430\n",
      "-----------------------------------------------------\n",
      "Test Sequences for TALA: 2275905\n",
      "-----------------------------------------------------\n",
      "Test Sequences for VARIOS: 866555\n",
      "-----------------------------------------------------\n",
      "==========================================================\n",
      "9619435 total Test sequences generated.\n",
      "9619435 total Test dates generated.\n",
      "9619435 total Test indices generated.\n",
      "==========================================================\n",
      "9619435 total Test targets generated.\n",
      "9619435 total Test target dates generated.\n",
      "9619435 total Test target indices generated.\n",
      "==========================================================\n"
     ]
    }
   ],
   "source": [
    "train_set = create_sequences(train_df_dict, seq_len=SEQ_LEN, forecast_h=FORECAST_H)\n",
    "test_set = create_sequences(\n",
    "    test_df_dict, seq_len=SEQ_LEN, forecast_h=FORECAST_H, step=\"Test\"\n",
    ")\n",
    "\n",
    "validate_dimensions(train_set, forecast=True)\n",
    "validate_dimensions(test_set, forecast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"../data/prep_data/train_set.npz\", **train_set)\n",
    "np.savez(f\"../data/prep_data/test_set.npz\", **test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
